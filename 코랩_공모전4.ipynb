{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPaYwHIciIwp68VTUZjIqlz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1c672eaa7bf448d19001a6817e946088": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f806d462eefe4fadbd153611c824310b",
              "IPY_MODEL_1de4fbacb29c49ccb9b2b45e4bf77885",
              "IPY_MODEL_e37fcde4e8b84682a1482b1e96e92e8e"
            ],
            "layout": "IPY_MODEL_4c9d98109a874d89b11129e2a0924761"
          }
        },
        "f806d462eefe4fadbd153611c824310b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7dcf4b53791440bf85e25bc7aff0f00e",
            "placeholder": "​",
            "style": "IPY_MODEL_07d24aa4b4b341ce950f48c2af3b9dbf",
            "value": "Map:  23%"
          }
        },
        "1de4fbacb29c49ccb9b2b45e4bf77885": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a501102200b04b23b57ab394692bf320",
            "max": 35233,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_65d36c90dfc84d63affc8ad0cb58926b",
            "value": 8000
          }
        },
        "e37fcde4e8b84682a1482b1e96e92e8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ea60e5ad3314a32b588ef3bca7c3fd5",
            "placeholder": "​",
            "style": "IPY_MODEL_5e6db53bd861427fa477b467a611aeae",
            "value": " 8000/35233 [00:16&lt;01:07, 400.70 examples/s]"
          }
        },
        "4c9d98109a874d89b11129e2a0924761": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dcf4b53791440bf85e25bc7aff0f00e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07d24aa4b4b341ce950f48c2af3b9dbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a501102200b04b23b57ab394692bf320": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65d36c90dfc84d63affc8ad0cb58926b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0ea60e5ad3314a32b588ef3bca7c3fd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e6db53bd861427fa477b467a611aeae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Minseos/KISTI_AI/blob/main/%EC%BD%94%EB%9E%A9_%EA%B3%B5%EB%AA%A8%EC%A0%844.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install datasets\n",
        "# !pip install transformers\n"
      ],
      "metadata": {
        "id": "fwHZz3zmnYoj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoaMbL8OoMEN",
        "outputId": "c85dd37a-bd2e-41f1-c1dd-9adaa39651fc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "1c672eaa7bf448d19001a6817e946088",
            "f806d462eefe4fadbd153611c824310b",
            "1de4fbacb29c49ccb9b2b45e4bf77885",
            "e37fcde4e8b84682a1482b1e96e92e8e",
            "4c9d98109a874d89b11129e2a0924761",
            "7dcf4b53791440bf85e25bc7aff0f00e",
            "07d24aa4b4b341ce950f48c2af3b9dbf",
            "a501102200b04b23b57ab394692bf320",
            "65d36c90dfc84d63affc8ad0cb58926b",
            "0ea60e5ad3314a32b588ef3bca7c3fd5",
            "5e6db53bd861427fa477b467a611aeae"
          ]
        },
        "id": "aeRUPWLznHuF",
        "outputId": "211cdf69-45b0-433c-f18f-e7d6d6b1f6a1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/35233 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c672eaa7bf448d19001a6817e946088"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import json\n",
        "from datasets import Dataset\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "# JSON 파일 경로\n",
        "json_file_path = \"/content/drive/MyDrive/라벨링데이터2.json\"\n",
        "\n",
        "# JSON 파일을 KcBERT 학습용 텍스트 데이터로 변환\n",
        "def convert_json_to_dataset(json_file_path):\n",
        "    with open(json_file_path, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    qa_pairs = []\n",
        "    for item in data:\n",
        "        question = item.get(\"question\")\n",
        "        answer = item.get(\"answer\")\n",
        "        if question and answer:\n",
        "            qa_pairs.append({\"question\": question, \"answer\": answer})\n",
        "\n",
        "    dataset = Dataset.from_list(qa_pairs)\n",
        "    return dataset\n",
        "\n",
        "# 1. 데이터를 변환하여 Hugging Face Dataset으로 저장\n",
        "qa_dataset = convert_json_to_dataset(json_file_path)\n",
        "\n",
        "# 2. 토크나이저 로드\n",
        "model_name = \"beomi/kcbert-base\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# 3. 데이터셋 토크나이즈\n",
        "def preprocess_data(examples):\n",
        "    return tokenizer(examples['question'], truncation=True, padding=\"max_length\", max_length=128)\n",
        "\n",
        "tokenized_dataset = qa_dataset.map(preprocess_data, batched=True)\n",
        "\n",
        "print(f\"데이터셋 크기: {len(tokenized_dataset)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# JSON 파일이 제대로 열리는지 확인\n",
        "with open(json_file_path, 'r', encoding='utf-8') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# 파일 내 첫 번째 항목을 출력하여 구조 확인\n",
        "print(f\"첫 번째 항목: {data[0]}\")\n",
        "print(f\"총 항목 수: {len(data)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qX6ng5tCq0SF",
        "outputId": "40976246-1738-4971-e9f9-212c476cf52b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "첫 번째 항목: {'question': '우리 사장이나 간부들이 이것을 대단히 소홀하게 중요하지 않게 생각하는데 끝까지 내 이야기에 대한 답변이 나오지 않았습니다.  공역문제인데 아까 공역을 전부 예를 들었습니다마는 가령 미공군 매향리 사격장, 한ㆍ미합동훈련장 또 여주 공군사격장, 수도권 비행금지구역, 휴전선 비행금지구역 이렇게 공역이 되어 있는데 앞으로 허브공항으로서 많은 비행기가 오는 곳에 공역이 도처에 있어요. 과연 그 공역을 피해 갈 수 있을 것인가에 대한 어려움을 우리 건교부하고 미8군하고 국방부하고 협의해서 공역문제는 사전에 합의를 보아야 할 문제인데 이것에 대해서 사장은 어떤 생각을 가지고 있느냐고 물어 보았습니다. 답변을 해주십시오.', '회의번호': 30045, '질의응답번호': 1, '회의구분': '국정감사', '위원회': '건설교통위원회', '회의일자': '2000年10月19日(木)', '질문자': '3337', '질문자_ISNI': '0000000463657210', 'answer': '서면으로 답변을 드리려고 했습니다마는 공역문제는 너무 중요한 문제입니다. 그리고 당장은 아니지만 2, 3년 앞을 내다보면 매우 심각한 문제입니다. 미국 정부에서도 그 심각성을 인정하고 있습니다. 그래서 제가 알기로는 건교부에서 국방부, 미 당국과도 협의를 이미 진행하고 있습니다.   그래서 공역을 변경하기로 일부 합의되어서 저희 공항개항과 더불어 현재의 공역보다도 많이 여유를 갖게 되어 있습니다. 그리고 근본적인 문제는 앞으로 한ㆍ미간 또는 국내에서 국방부와 협의가 계속 진행될 것으로 알고 있습니다.', '답변자': ' ', '답변자_ISNI': ' '}\n",
            "총 항목 수: 35233\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from datasets import Dataset\n",
        "\n",
        "# JSON 파일을 KcBERT 학습용 텍스트 데이터로 변환\n",
        "def convert_json_to_dataset(json_file_path):\n",
        "    with open(json_file_path, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    qa_pairs = []\n",
        "    for item in data:\n",
        "        question = item.get(\"question\", \"\")\n",
        "        answer = item.get(\"answer\", \"\")\n",
        "\n",
        "        if question and answer:  # question과 answer가 있는 경우에만 추가\n",
        "            qa_pairs.append({\n",
        "                \"question\": question,\n",
        "                \"answer\": answer,\n",
        "                # 'context' 대신 바로 question과 answer를 사용\n",
        "            })\n",
        "\n",
        "    dataset = Dataset.from_list(qa_pairs)\n",
        "    return dataset\n",
        "\n",
        "# 데이터셋 변환\n",
        "qa_dataset = convert_json_to_dataset(json_file_path)\n",
        "print(f\"데이터셋 크기: {len(qa_dataset)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqbNvDwmnMa8",
        "outputId": "eb82b50d-e85f-4f72-f4c4-e5b795e1c199"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터셋 크기: 35233\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDU-UOLpqPyB",
        "outputId": "74a6f354-ff06-4aa7-d882-2f8ff8bace32"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "토크나이즈된 데이터셋 크기: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 토크나이즈 및 학습 진행 코드:"
      ],
      "metadata": {
        "id": "bZoS_JaOqDhv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizerFast, BertForQuestionAnswering, Trainer, TrainingArguments\n",
        "from datasets import Dataset\n",
        "\n",
        "# 1. Fast 토크나이저 로드\n",
        "model_name = \"beomi/kcbert-base\"\n",
        "tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
        "\n",
        "# 2. 데이터셋 전처리 (question과 answer만 사용)\n",
        "def preprocess_data(examples):\n",
        "    # 질문과 답변을 배치 단위로 처리 (리스트로 제공됨)\n",
        "    tokenized_examples = tokenizer(\n",
        "        examples[\"question\"],\n",
        "        examples[\"answer\"],  # answer를 context 대신 사용\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=300,  # 최대 길이를 300으로 변경\n",
        "        return_offsets_mapping=True  # 오프셋 매핑을 사용하여 답변 위치 계산\n",
        "    )\n",
        "\n",
        "    # 배치 단위로 각 질문/답변의 시작과 끝 위치를 계산\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "\n",
        "    for i, (context, answer) in enumerate(zip(examples[\"answer\"], examples[\"answer\"])):\n",
        "        start_pos = context.find(answer)\n",
        "        end_pos = start_pos + len(answer)\n",
        "\n",
        "        if start_pos == -1:\n",
        "            start_pos = 0\n",
        "            end_pos = 0\n",
        "\n",
        "        # 오프셋 매핑을 사용하여 실제 토큰화된 문장에서 시작과 끝 위치 찾기\n",
        "        offsets = tokenized_examples[\"offset_mapping\"][i]\n",
        "        token_start_index = 0\n",
        "        token_end_index = len(offsets) - 1\n",
        "\n",
        "        for idx, offset in enumerate(offsets):\n",
        "            if offset[0] <= start_pos < offset[1]:\n",
        "                token_start_index = idx\n",
        "            if offset[0] <= end_pos < offset[1]:\n",
        "                token_end_index = idx\n",
        "\n",
        "        start_positions.append(token_start_index)\n",
        "        end_positions.append(token_end_index)\n",
        "\n",
        "    tokenized_examples[\"start_positions\"] = start_positions\n",
        "    tokenized_examples[\"end_positions\"] = end_positions\n",
        "\n",
        "    return tokenized_examples\n",
        "\n",
        "# 3. 데이터셋에 전처리 적용\n",
        "tokenized_dataset = qa_dataset.map(preprocess_data, batched=True)\n",
        "\n",
        "# 4. KcBERT 모델 로드 (질문-답변용)\n",
        "model = BertForQuestionAnswering.from_pretrained(model_name)\n",
        "\n",
        "# 5. 학습 하이퍼파라미터 설정\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./kcbert_finetuned\",   # 학습된 모델 저장 위치\n",
        "    overwrite_output_dir=True,         # 기존 저장된 모델 덮어쓰기\n",
        "    num_train_epochs=1,                # 학습할 에폭 수\n",
        "    per_device_train_batch_size=8,    # 배치 크기\n",
        "    save_steps=20_000,                 # 체크포인트 저장 간격\n",
        "    save_total_limit=2,                # 체크포인트 최대 저장 개수\n",
        "    logging_dir=\"./logs\",              # 로그 저장 디렉토리\n",
        "    logging_steps=500,                 # 로그 기록 간격\n",
        "    remove_unused_columns=False,       # 모든 열을 사용하도록 설정\n",
        "    fp16=True,                         # 16비트 부동소수점 사용\n",
        ")\n",
        "\n",
        "# 6. Trainer 설정\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    data_collator=lambda data: {\n",
        "        \"input_ids\": torch.tensor([f[\"input_ids\"] for f in data]),\n",
        "        \"attention_mask\": torch.tensor([f[\"attention_mask\"] for f in data]),\n",
        "        \"token_type_ids\": torch.tensor([f[\"token_type_ids\"] for f in data]),\n",
        "        \"start_positions\": torch.tensor([f[\"start_positions\"] for f in data]),\n",
        "        \"end_positions\": torch.tensor([f[\"end_positions\"] for f in data]),\n",
        "    },\n",
        ")\n",
        "\n",
        "# 7. 모델 학습 시작\n",
        "trainer.train()\n",
        "\n",
        "# 8. 학습 완료된 모델 저장\n",
        "trainer.save_model('./kcbert_finetuned')\n",
        "tokenizer.save_pretrained('./kcbert_finetuned')\n",
        "\n",
        "print(\"KcBERT 모델 미세 조정 완료 및 저장되었습니다!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "npG3abvTnMXc",
        "outputId": "2dbdd3cb-d1df-47fd-e15f-831f3b3ed0c5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'qa_dataset' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-bb28eefa1838>\u001b[0m in \u001b[0;36m<cell line: 53>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m# 3. 데이터셋에 전처리 적용\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0mtokenized_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqa_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;31m# 4. KcBERT 모델 로드 (질문-답변용)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'qa_dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 모델 평가 및 테스트"
      ],
      "metadata": {
        "id": "QdJNSPTmsUhC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizerFast, BertForQuestionAnswering\n",
        "\n",
        "# 학습된 모델과 토크나이저 로드\n",
        "model = BertForQuestionAnswering.from_pretrained('./kcbert_finetuned')\n",
        "tokenizer = BertTokenizerFast.from_pretrained('./kcbert_finetuned')\n",
        "\n",
        "# 모델을 평가 모드로 설정\n",
        "model.eval()\n",
        "\n",
        "# 질문과 문맥을 정의\n",
        "question = \"여주 공군사격장은 어디에 위치해 있나요?\"\n",
        "context = \"\"\"미공군 매향리 사격장, 한ㆍ미합동훈련장, 여주 공군사격장, 수도권 비행금지구역, 휴전선 비행금지구역 이렇게 공역이 되어 있는데...\"\"\"\n",
        "\n",
        "# 질문과 문맥을 토크나이즈\n",
        "inputs = tokenizer(question, context, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "\n",
        "# 모델 예측\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "# 예측된 답변 위치 추출\n",
        "start_idx = torch.argmax(outputs.start_logits)\n",
        "end_idx = torch.argmax(outputs.end_logits) + 1\n",
        "\n",
        "# 예측된 답변 디코딩\n",
        "answer = tokenizer.decode(inputs['input_ids'][0][start_idx:end_idx])\n",
        "print(f\"질문: {question}\")\n",
        "print(f\"답변: {answer}\")\n"
      ],
      "metadata": {
        "id": "msnbuMK8nMTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. 모델 배포"
      ],
      "metadata": {
        "id": "CjJTQ7F_sw6Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "from transformers import BertTokenizerFast, BertForQuestionAnswering\n",
        "import torch\n",
        "\n",
        "# 학습된 KcBERT 모델과 토크나이저 로드\n",
        "model_path = \"./kcbert_finetuned\"\n",
        "tokenizer = BertTokenizerFast.from_pretrained(model_path)\n",
        "model = BertForQuestionAnswering.from_pretrained(model_path)\n",
        "\n",
        "# Streamlit 애플리케이션 구성\n",
        "st.title(\"KcBERT 질문-답변 시스템\")\n",
        "\n",
        "context = st.text_area(\"문맥을 입력하세요\", \"여기에 문맥을 입력하세요.\")\n",
        "question = st.text_input(\"질문을 입력하세요\")\n",
        "\n",
        "if st.button(\"답변 생성\"):\n",
        "    if question and context:\n",
        "        inputs = tokenizer(question, context, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "        start_idx = torch.argmax(outputs.start_logits)\n",
        "        end_idx = torch.argmax(outputs.end_logits) + 1\n",
        "        answer = tokenizer.decode(inputs['input_ids'][0][start_idx:end_idx])\n",
        "        st.write(f\"답변: {answer}\")\n",
        "    else:\n",
        "        st.write(\"질문과 문맥을 입력해주세요.\")\n"
      ],
      "metadata": {
        "id": "BVPvlrU_nMRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. 추가 학습 (Fine-tuning)\n",
        "학습이 충분하지 않거나 더 많은 데이터를 사용해 성능을 향상시키고 싶다면, 추가로 학습을 진행할 수 있습니다. 이를 통해 모델의 성능을 더욱 개선할 수 있습니다.\n",
        "\n",
        "4. 모델 평가 (Evaluation)\n",
        "학습된 모델을 평가하기 위한 데이터셋을 준비하고, 정확도(accuracy), F1 점수 등 평가 지표를 통해 모델 성능을 검증할 수 있습니다."
      ],
      "metadata": {
        "id": "Xwm6F7POs08d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_metric\n",
        "\n",
        "# 평가 지표 설정\n",
        "metric = load_metric(\"accuracy\")\n",
        "\n",
        "# 평가 데이터셋에 대해 예측 수행\n",
        "for example in eval_dataset:\n",
        "    inputs = tokenizer(example[\"question\"], example[\"context\"], return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    start_idx = torch.argmax(outputs.start_logits)\n",
        "    end_idx = torch.argmax(outputs.end_logits) + 1\n",
        "    predicted_answer = tokenizer.decode(inputs['input_ids'][0][start_idx:end_idx])\n",
        "\n",
        "    # 평가 메트릭 계산\n",
        "    metric.add(prediction=predicted_answer, reference=example[\"answer\"])\n",
        "\n",
        "# 최종 평가 결과 출력\n",
        "print(metric.compute())\n"
      ],
      "metadata": {
        "id": "NH9Nev_DnMP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Hugging Face에 모델 업로드"
      ],
      "metadata": {
        "id": "5kEnrKlQs4rv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()\n",
        "\n",
        "# 모델 업로드\n",
        "model.push_to_hub(\"your-model-name\")\n",
        "tokenizer.push_to_hub(\"your-model-name\")\n"
      ],
      "metadata": {
        "id": "Lz__KmaAnMOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DrbC_YlunMMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ub-vYgr-nMKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yEhcGQE0nMHw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}